import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain_community.vectorstores import Chroma # LangChain 1.0ë¶€í„° ì‚¬ë¼ì§ˆ ì˜ˆì •. ë” ì´ìƒ ê¶Œì¥ë˜ì§€ ì•ŠìŒ
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from pydantic import SecretStr
import time



# .env íŒŒì¼ ë¡œë“œ
start = time.time()
_ = load_dotenv()
print(f"âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {time.time() - start:.2f}ì´ˆ")

# ë¬¸ì„œ ë¡œë“œ
loader = TextLoader("rag_sample.txt", encoding="utf-8")
documents = loader.load()

# ë¬¸ì„œ ìª¼ê°œê¸°
start = time.time()
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
splits = splitter.split_documents(documents)
print(f"âœ… ë¬¸ì„œ ë¶„í•  ì™„ë£Œ: {time.time() - start:.2f}ì´ˆ")

# í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (ë¡œì»¬ HuggingFace ëª¨ë¸ ì‚¬ìš©)
# all-MiniLM-L6-v2 : ì¼ë°˜ì ì´ê³  ì •í™•ë„ ì¢‹ìŒ, paraphrase-MiniLM-L3-v2 : í›¨ì”¬ ì‘ê³  ë¹ ë¦„(ì†ë„ê°€ ì¤‘ìš”í•  ë•Œ ì¶”ì²œ)
start = time.time()
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ìµœì í™” ë¶€ë¶„
if os.path.exists("rag_db"):
    print("ğŸ’¬ ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ..")
    vectorstore = Chroma(persist_directory="rag_db", embedding_function=embedding)
else:
    print("ğŸ’¬ ìƒˆë¡œìš´ ë²¡í„° DB ìƒì„±..")
    vectorstore = Chroma.from_documents(splits, embedding, persist_directory="rag_db")
    # vectorstore.persist() -> deprecated!! ìë™ ì €ì¥ë˜ì–´ í˜¸ì¶œ í•„ìš” ì—†ìŒ
    print("âœ… ì €ì¥ ì™„ë£Œ!")
    print(f"âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ: {time.time() - start:.2f}ì´ˆ")


# Groq API ê¸°ë°˜ LLM
llm = ChatOpenAI(
    model="gemma2-9b-it",
    temperature=0,
        api_key=SecretStr(os.getenv("OPENAI_API_KEY") or "") if os.getenv("OPENAI_API_KEY") else None,
        base_url=os.getenv("OPENAI_API_BASE")
)

# RAG ì²´ì¸ ìƒì„±
qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever())

# ì§ˆë¬¸ ì‹¤í–‰
# question = "SPEROì˜ êµ¬ì¡°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
# question = "SPEROì˜ êµ¬ì¡°ì—ì„œ Backendë¥¼ êµ¬ì„±í•˜ëŠ” ìš”ì†Œë“¤ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
question = "SPEROì˜ êµ¬ì¡°ì—ì„œ Frontendì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."
response = qa_chain.invoke(question)

print("ğŸ’¬ ì‘ë‹µ(ì§ˆë¬¸):\n", response.get("query"))
print("ğŸ’¬ ì‘ë‹µ(ë‹µë³€):\n", response.get("result"))